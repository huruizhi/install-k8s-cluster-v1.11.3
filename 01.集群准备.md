# 集群准备
## 集群机器

- k8s-server-1：192.168.0.162
- k8s-server-2：192.168.0.165
- k8s-server-3：192.168.0.166

## 主机名

设置永久主机名称，然后重新登录:

```
$ sudo hostnamectl set-hostname k8s-server-1# 将 k8s-server-1 替换为当前主机名
```

修改每台机器的`/etc/hosts`文件，添加主机名和 IP 的对应关系：

```
echo "

192.168.0.162 k8s-server-1
192.168.0.165 k8s-server-2
192.168.0.166 k8s-server-3

" >> /etc/hosts
```

## 添加 k8s 和 docker 账户

在每台机器上添加 k8s 账户，可以无密码 sudo：

```
sudo useradd -m k8s
sudo sh -c 'echo 123456 | passwd k8s --stdin' # 为 k8s 账户设置密码
## 编辑 visudo
sudo visudo
sudo grep '%wheel.*NOPASSWD: ALL' /etc/sudoers
%wheel    ALL=(ALL)    NOPASSWD: ALL
sudo gpasswd -a k8s wheel
```

在每台机器上添加 docker 账户，将 k8s 账户添加到 docker 组中，同时配置 dockerd 参数：

```
sudo useradd -m docker
sudo gpasswd -a k8s docker
sudo mkdir -p  /etc/docker/
cat /etc/docker/daemon.json
{
    "registry-mirrors": ["https://hub-mirror.c.163.com", "https://docker.mirrors.ustc.edu.cn"],
    "max-concurrent-downloads": 20
}
```

## 无密码 ssh 登录其它节点

如果没有特殊指明，本文档的所有操作**均在 k8s-server-1 节点上执行**，然后远程分发文件和执行命令。

设置 kube-node1 可以无密码登录**所有节点**的 k8s 和 root 账户：

```
ssh-keygen -t rsa
ssh-copy-id root@k8s-server-1
ssh-copy-id root@k8s-server-2
ssh-copy-id root@k8s-server-3
ssh-copy-id k8s@k8s-server-3
ssh-copy-id k8s@k8s-server-2
ssh-copy-id k8s@k8s-server-1
```

## 将可执行文件路径 /opt/k8s/bin 添加到 PATH 变量中

在每台机器上添加环境变量：

```
sudo sh -c "echo 'PATH=/opt/k8s/bin:$PATH:$HOME/bin:$JAVA_HOME/bin' >>/root/.bashrc"
echo 'PATH=/opt/k8s/bin:$PATH:$HOME/bin:$JAVA_HOME/bin' >>~/.bashrc
```

## 安装依赖包

在每台机器上安装依赖包：

CentOS:

```
sudo yum install -y epel-release
sudo yum install -y conntrack ipvsadm ipset jq sysstat curl iptables libseccomp
```

## 关闭防火墙

在每台机器上关闭防火墙：

```
sudo systemctl stop firewalld
sudo systemctl disable firewalld
sudo iptables -F && sudo iptables -X && sudo iptables -F -t nat && sudo iptables -X -t nat
sudo sudo iptables -P FORWARD ACCEPT
```

## 关闭 swap 分区

如果开启了 swap 分区，kubelet 会启动失败(可以通过将参数 --fail-swap-on 设置为 false 来忽略 swap on)，故需要在每台机器上关闭 swap 分区：

```
sudo swapoff -a
```

为了防止开机自动挂载 swap 分区，可以注释`/etc/fstab`中相应的条目：

```
sudo sed -i '/ swap / s/^\(.*\)$/#\1/g' /etc/fstab
```

## 关闭 SELinux

关闭 SELinux，否则后续 K8S 挂载目录时可能报错`Permission denied`：

```
sudo setenforce 0
# 使用root登录
echo 'SELINUX=disabled' > /etc/selinux/config
```

- 修改配置文件，永久生效；

## 关闭 dnsmasq

linux 系统开启了 dnsmasq 后(如 GUI 环境)，将系统 DNS Server 设置为 127.0.0.1，这会导致 docker 容器无法解析域名，需要关闭它：

```
sudo service dnsmasq stop
sudo systemctl disable dnsmasq
```

## 设置系统参数

```
cat > kubernetes.conf <<EOF
 =1
net.bridge.bridge-nf-call-ip6tables=1
net.ipv4.ip_forward=1
vm.swappiness=0
vm.overcommit_memory=1
vm.panic_on_oom=0
fs.inotify.max_user_watches=89100
EOF
sudo cp kubernetes.conf /etc/sysctl.d/kubernetes.conf
sudo sysctl -p /etc/sysctl.d/kubernetes.conf
sudo mount -t cgroup -o cpu,cpuacct none /sys/fs/cgroup/cpu,cpuacct
```

## 加载内核模块

```
sudo modprobe br_netfilter
sudo modprobe ip_vs
```

## 设置系统时区

```
# 调整系统 TimeZone
sudo timedatectl set-timezone Asia/Shanghai

# 将当前的 UTC 时间写入硬件时钟
sudo timedatectl set-local-rtc 0

# 重启依赖于系统时间的服务
sudo systemctl restart rsyslog
sudo systemctl restart crond
```

## 创建目录

在每台机器上创建目录：

```

sudo mkdir -p /application/k8s/bin
sudo chown -R k8s /application/k8s
sudo ln -s /application/k8s /opt/k8s

sudo sudo mkdir -p /application/kubernetes/cert
sudo chown -R k8s /application/kubernetes
sudo ln -s /application/kubernetes /etc/kubernetes

sudo mkdir -p /application/etcd/cert
sudo chown -R k8s /application/etcd/cert
sudo ln -s /application/etcd /etc/etcd

sudo mkdir -p /var/lib/etcd && sudo chown -R k8s /var/lib/etcd
```

## 集群环境变量

后续的部署步骤将使用下面定义的全局环境变量，请根据自己的机器、网络情况修改：

```
#!/usr/bin/bash

# 生成 EncryptionConfig 所需的加密 key
ENCRYPTION_KEY=$(head -c 32 /dev/urandom | base64)

# 最好使用 当前未用的网段 来定义服务网段和 Pod 网段

# 服务网段，部署前路由不可达，部署后集群内路由可达(kube-proxy 和 ipvs 保证)
SERVICE_CIDR="10.254.0.0/16"

# Pod 网段，建议 /16 段地址，部署前路由不可达，部署后集群内路由可达(flanneld 保证)
CLUSTER_CIDR="172.30.0.0/16"

# 服务端口范围 (NodePort Range)
export NODE_PORT_RANGE="1-65535"

# 集群各机器 IP 数组
export NODE_IPS=(192.168.0.162 192.168.0.165 192.168.0.166)

# 集群各 IP 对应的 主机名数组
export NODE_NAMES=(k8s-server-1 k8s-server-2 k8s-server-3)

# kube-apiserver 的 VIP（HA 组件 keepalived 发布的 IP）
export MASTER_VIP=192.168.0.200

# kube-apiserver VIP 地址（HA 组件 haproxy 监听 8443 端口）
export KUBE_APISERVER="https://${MASTER_VIP}:8443"

# HA 节点，VIP 所在的网络接口名称
export VIP_IF="enp3s0"

# etcd 集群服务地址列表
export ETCD_ENDPOINTS="https://192.168.0.162:2379,https://192.168.0.165:2379,https://192.168.0.166:2379"

# etcd 集群间通信的 IP 和端口
export ETCD_NODES="k8s-server-1=https://192.168.0.162:2380,k8s-server-2=https://192.168.0.165:2380,k8s-server-3=https://192.168.0.166:2380"

# flanneld 网络配置前缀
export FLANNEL_ETCD_PREFIX="/kubernetes/network"

# kubernetes 服务 IP (一般是 SERVICE_CIDR 中第一个IP)
export CLUSTER_KUBERNETES_SVC_IP="10.254.0.1"

# 集群 DNS 服务 IP (从 SERVICE_CIDR 中预分配)
export CLUSTER_DNS_SVC_IP="10.254.0.2"

# 集群 DNS 域名
export CLUSTER_DNS_DOMAIN="cluster.local."

# 将二进制目录 /opt/k8s/bin 加到 PATH 中
export PATH=/opt/k8s/bin:$PATH
```

后续部署时会提示导入该脚本；

## 分发集群环境变量定义脚本

把全局变量定义脚本拷贝到所有节点的 /opt/k8s/bin 目录：

```
source environment.sh
for node_ip in ${NODE_IPS[@]}
  do
    echo ">>> ${node_ip}"
    scp environment.sh k8s@${node_ip}:/opt/k8s/bin/
    ssh k8s@${node_ip} "chmod +x /opt/k8s/bin/*"
  done
```

## 参考

系统内核相关参数参考：
[https://docs.openshift.com/enterprise/3.2/admin_guide/overcommit.html](https://docs.openshift.com/enterprise/3.2/admin_guide/overcommit.html)
